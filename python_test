#!/usr/bin/env python

#a Imports
from OpenGL.GLUT import *
from OpenGL.GL import *
import gjslib_c
import math
img_png_n=0

#a Support functions
#f init_opengl
def init_opengl():
    glutInit(sys.argv)
    glutInitDisplayMode(GLUT_3_2_CORE_PROFILE |GLUT_DOUBLE | GLUT_RGB | GLUT_DEPTH)
    glutInitWindowSize(64,64)
    glutCreateWindow("self.window_title")

#f save_as_png
def save_as_png(texture, filename):
        b = gjslib_c.filter(filter="save:%s(0)"%filename)
        b.textures([texture])
        b.compile()
        b.execute()
        pass

#f alu_test
def alu_test(ops):
    for (ts, op, save_filename) in ops:
            b = gjslib_c.filter(filter="glsl:alu_buffers(0,0,0)")
            b.define("OP",op)
            b.compile()
            b.textures( [tb[i] for i in ts] )
            b.execute()
            save_as_png(tb[ts[-1]],save_filename)
            pass
    pass

#f v_of_q
def v_of_q(q):
    q = q.copy().normalize()
    return q.rotate_vector((0,0,1))

#f quaternion_average
def quaternion_average(qs, verbose=False):
    quaternion = gjslib_c.quaternion
    vf = [0,0,0]
    vu = [0,0,0]
    for q in qs:
        nvf = q.rotate_vector((0,0,1))
        nvu = q.rotate_vector((1,0,0))
        for i in range(3):
            vf[i] += nvf[i]
            vu[i] += nvu[i]
            pass
        pass
    if verbose: print vf, vu,qs[0]
    return quaternion().lookat(tuple(vf),tuple(vu))

#a Toplevel 1
print "init opengl"        
init_opengl()
# a = gjslib_c.texture(filename='images/IMG_2162.JPG')

print "Create textures"
tb = []
size = 1024
for i in range(12):
        tb.append(gjslib_c.texture(width=size, height=size))
        pass
print tb[0].width, tb[0].height


# b = gjslib_c.filter(filter="glsl:yuv_from_rgb(1,3)&-DINTENSITY_YSCALE=(3456.0/5184.0)&-DINTENSITY_XOFS=0.0&-DINTENSITY_XSCALE=1.0&-DINTENSITY_YOFS=0.0")
# b.define("INTENSITY_YSCALE","3.0")
# b.define("INTENSITY_YSCALE",remove=1)
# b.compile()

#a Filter classes
#c c_filter
class c_filter(object):
    filter_text = 'glsl:yuv_from_rgb(1,2)'
    defines = {}
    parameters = {}
    def __init__(self, extra_parameters={}, extra_defines={}):
        self.f = gjslib_c.filter(filter=self.filter_text)
        for u in extra_parameters:
            self.f.parameter(u,extra_parameters[u])
        for u in self.parameters:
            if u not in extra_parameters:    
                self.f.parameter(u,self.parameters[u])
        for d in extra_defines:
            self.f.define(d,str(extra_defines[d]))
            pass
        for d in self.defines:
            if d not in extra_defines:
                self.f.define(d,str(self.defines[d]))
                pass
            pass
        self.f.compile()
        pass
    def set_parameters(self, parameters={}):
        for p in parameters:
            self.f.parameter(p,parameters[p])
            pass
        pass
    def set_projections(self, projections=(None,None), num_x_divisions=None, num_y_divisions=None):
        if projections[0] and projections[1]: self.f.projections(projections[0], projections[1])
        if num_x_divisions: self.f.parameter("num_x_divisions",num_x_divisions)
        if num_y_divisions: self.f.parameter("num_y_divisions",num_y_divisions)
        pass
    def execute(self,textures):
        self.f.textures(textures)
        self.f.execute()
        pass
    pass

#c c_mandelbrot_filter
class c_mandelbrot_filter(c_filter):
    filter_text = 'glsl:mandelbrot(0,1)'

#c c_alu_filter
class c_alu_filter(c_filter):
    filter_text = 'glsl:alu_buffers(0,0,0)'

#c c_yuv_from_rgb
class c_yuv_from_rgb(c_filter):
    filter_text = 'glsl:yuv_from_rgb(1,2)'

#c c_gauss_filter_y
class c_gauss_filter_y(c_filter):
    filter_text = 'glsl:gauss(1,2)'
    defines = {"X_NOT_Y":"false", "NUM_WEIGHTS":"9", "WEIGHTS":"gauss_offset_weights9"}

#c c_gauss_filter_x
class c_gauss_filter_x(c_filter):
    filter_text = 'glsl:gauss(1,2)'
    defines = {"X_NOT_Y":"true", "NUM_WEIGHTS":"9", "WEIGHTS":"gauss_offset_weights9"}
        
#c c_sobel_filter
class c_sobel_filter(c_filter):
    filter_text = 'glsl:convolve_2d(1,2)'
    defines = {"NUM_WEIGHTS":"9", "OFFSET_WEIGHTS":"sobel_weights"}

#c c_harris_filter
class c_harris_filter(c_filter):
    filter_text = 'glsl:harris(1,2)'
    defines = {"NUM_OFFSETS":"25", "OFFSETS":"offsets_2d_25"}

#c c_circle_dft_filter
class c_circle_dft_filter(c_filter):
    filter_text = "glsl:circle_dft(2,4)"
    defines = { "NUM_CIRCLE_STEPS":"8", 
                "DFT_CIRCLE_RADIUS":"8",
                "CIRCLE_COMPONENT":"r" }

#c c_circle_dft_diff_filter
class c_circle_dft_diff_filter(c_filter):
    filter_text = "glsl:circle_dft_diff(2,4,5)"
    parameters = {"uv_base_x":0.0, "uv_base_y":0.0}

#c c_circle_dft_diff_combine_filter
class c_circle_dft_diff_combine_filter(c_filter):
    filter_text = "glsl:circle_dft_diff_combine(1,2,3,4,0)"
    defines = {"DISCRETE_CIRCLE_OFS":"discrete_circle_offsets_4_32",
               "NUM_OFFSETS":32}

#c c_find_filter
class c_find_filter(c_filter):
    filter_text = "find:a(1)"

#c c_windowed_equalization_filter
class c_windowed_equalization_filter(c_filter):
    filter_text = 'glsl:windowed_equalization(2,4)'
    defines = {"NUM_OFFSETS":81, "OFFSETS":"offsets_2d_81"}

#a Match classes
#c c_image_match
class c_image_match(object):
    radius=4
    windowed_equalization = False
    max_corners=3
    max_matches_per_corner=3
    def __init__(self, radius=4):
        # radius must be 4 at the moment as circle_dft_diff_combine_filter is fixed    
        self.copy_img = c_alu_filter(extra_defines={"OP":"src_a"})
        self.equalize = c_windowed_equalization_filter()
        self.harris = c_harris_filter()
        self.find_corners = c_find_filter(extra_parameters={"min_distance":5.0, "minimum":0.04, "max_elements":150})
        self.find_matches = c_find_filter(extra_parameters={"min_distance":2.5, "minimum":0.04,  "max_elements":150})
        self.circle_dft = c_circle_dft_filter(extra_defines={"DFT_CIRCLE_RADIUS":self.radius,
                                                             "CIRCLE_COMPONENT":"r",
                                                             })
        self.circle_dft_diff         = c_circle_dft_diff_filter()
        self.circle_dft_diff_combine = c_circle_dft_diff_combine_filter()
        pass
    def get_matches(self, tb):
        """tb must be at least 10 textures, and the first is the source image, second is the target image"""
        self.harris.execute( (tb[0],tb[4]) )

        if self.windowed_equalization: # do windowed equalization to remove brightness and contrastiness dependence - with loss of information
                self.copy_img.execute((tb[0],tb[0],tb[2]))
                self.equalize.execute((tb[2],tb[0]))
                self.copy_img.execute((tb[1],tb[1],tb[2]))
                self.equalize.execute((tb[2],tb[1]))
                pass
        self.circle_dft.execute((tb[0],tb[2]))
        self.circle_dft.execute((tb[1],tb[3]))
        self.find_corners.execute( (tb[4],) )

        print "Found %d corners"%(self.find_corners.f.num_points)
        corners = self.find_corners.f.points[:self.max_corners]
        matches = {}
        for i in range(len(corners)):
            pt = corners[i]
            xy = (pt[0],pt[1])
            for i, dxy in [(0,(1,0)), (1,(0,1)), (2,(-1,0)), (3,(0,-1))]:
                self.circle_dft_diff.set_parameters( {"uv_base_x":xy[0]+dxy[0]*self.radius,
                                                      "uv_base_y":xy[1]+dxy[1]*self.radius} )
                self.circle_dft_diff.execute( (tb[2], tb[3], tb[5+i]) )
                pass
            self.circle_dft_diff_combine.execute( (tb[5], tb[6], tb[7], tb[8], tb[9]) )
            self.find_matches.execute( (tb[9],) )
            matches[xy] = self.find_matches.f.points[0:self.max_matches_per_corner]
            pass
        return matches
    pass

#c c_quaternion_match
class c_quaternion_match(object):
    #f test_add
    @classmethod
    def test_add(cls, src_qs, tgt_qs, max_angle_diff):
        (src_axis, src_angle) = c_vector.axis_angle_of_quaternion_diff(src_qs[0], src_qs[1])
        (tgt_axis, tgt_angle) = c_vector.axis_angle_of_quaternion_diff(tgt_qs[0], tgt_qs[1])
        if abs(src_angle-tgt_angle)>=max_angle_diff/180.0*math.pi:
            return None
        if False:
            print "  Src/tgt axis/angle",src_axis,src_angle*180/math.pi,tgt_axis,tgt_angle*180/math.pi
            pass
        dq = c_vector.vector_diff((src_qs[0]/tgt_qs[0]).rotate_vector((0,0,1)),(src_qs[1]/tgt_qs[1]).rotate_vector((0,0,1)))
        #print "Abs:",c_vector.vector_length(dq),"   ",180.0/math.pi*abs(src_angle-tgt_angle),"  ",dq
        dq = c_vector.vector_length(dq)
        if abs(dq)>0.2: return None
        return cls(src_qs, tgt_qs, src_axis_angle=(src_axis, src_angle), tgt_axis_angle=(tgt_axis,tgt_angle))
    #f __init__
    def __init__(self, src_qs, tgt_qs, src_axis_angle=None, tgt_axis_angle=None ):
        self.src_qs = src_qs
        self.tgt_qs = tgt_qs
        self.src_axis_angle = src_axis_angle
        self.tgt_axis_angle = tgt_axis_angle
        self.src_from_tgt_orient = gjslib_c.quaternion()
        self.calculate()
        pass
    #f calculate
    def calculate(self):
        if self.src_axis_angle is None:
            self.src_axis_angle = c_vector.axis_angle_of_quaternion_diff(self.src_qs[0], self.src_qs[1])
            pass
        if self.tgt_axis_angle is None:
            self.tgt_axis_angle = c_vector.axis_angle_of_quaternion_diff(self.tgt_qs[0], self.tgt_qs[1])
            pass
        (src_axis, src_angle) = self.src_axis_angle
        (tgt_axis, tgt_angle) = self.tgt_axis_angle

        (diff_axis, diff_angle) = c_vector.axis_angle_from_v0_to_v1(src_axis, tgt_axis)
        sp0 = self.src_qs[0].rotate_vector((0,0,1))
        tp0 = self.tgt_qs[0].rotate_vector((0,0,1))

        src_angle_sp0 = math.atan2(c_vector.vector_length(c_vector.vector_product(sp0,diff_axis)),c_vector.dot_product(sp0,diff_axis))
        dst_angle_tp0 = math.atan2(c_vector.vector_length(c_vector.vector_product(tp0,diff_axis)),c_vector.dot_product(tp0,diff_axis))
        src_sp0_orient_to_diff_axis = gjslib_c.quaternion.of_rotation(src_axis, -src_angle_sp0)
        dst_tp0_orient_to_diff_axis = gjslib_c.quaternion.of_rotation(tgt_axis, -dst_angle_tp0)

        # diff_axis === src_sp0_orient_to_diff_axis.rotate_vector(sp0)
        # diff_axis === dst_tp0_orient_to_diff_axis.rotate_vector(tp0)

        # tgt_q = quaternion.of_rotation(tgt_axis, tgt_angle)
        # src_q = quaternion.of_rotation(src_axis, src_angle)
        # tp1 === tgt_q.rotate_vector(tp0)
        # tp1 == {dst_lp_35.orient(tgt_q*dst_orientation), (dst_lp_35.orientation_of_xy((t0[3]-512,t0[4]-512))).rotate_vector((0,0,1))
        # sp1 == {src_lp_35.orient(src_q*src_orientation), (src_lp_35.orientation_of_xy(data[src_q0][0])).rotate_vector((0,0,1))
        # dst_orient_gc_aligned = quaternion.of_rotation(axis=diff_axis, angle=-diff_angle, degrees=0) * dst_orientation
        # dst_lp_35.orient(dst_orient_gc_aligned)
        # t0p = dst_lp_35.orientation_of_xy((t0[3]-512,t0[4]-512))
        # t1p = dst_lp_35.orientation_of_xy((t1[3]-512,t1[4]-512))
        # tp0 = t0p.rotate_vector((0,0,1))
        # tp1 = t1p.rotate_vector((0,0,1))
        # tgt_axis = vector_product(tp0,tp1)
        # tgt_axis = vector_normalize(tgt_axis)

        self.src_from_tgt_orient = ~src_sp0_orient_to_diff_axis * gjslib_c.quaternion.of_rotation(axis=diff_axis, angle=-diff_angle, degrees=0) * dst_tp0_orient_to_diff_axis
        pass
    pass

#c c_quaternion_cluster
class c_quaternion_cluster(object):
    #f __init__
    def __init__(self, results):
        self.results = results
        pass
    #f find_centers
    def find_centers(self, qs, cxy, min_dist, min_min_dist, min_number, scale, max_iter):
        def q_dist_from_v(q,v):
            return c_vector.vector_length(c_vector.vector_diff(v_of_q(q),v))
        if max_iter==0:
            return (qs[:], cxy, min_dist, len(qs), max_iter)
        if min_dist < min_min_dist:
            return (qs[:], cxy, min_dist, len(qs), max_iter)
        max_min = 0
        allowed_qs = []
        
        for q in qs:
            d = q_dist_from_v(q,cxy)
            if (d<min_dist):
                if (d>max_min): max_min=d
                allowed_qs.append(q)
                pass
            pass
        if len(allowed_qs)<min_number:
            return (qs[:], cxy, min_dist, len(allowed_qs), max_iter)
        tq = quaternion_average(allowed_qs)
        return self.find_centers(allowed_qs, v_of_q(tq), max_min*scale, min_min_dist, min_number, scale, max_iter-1)
    #f find_clusters
    def find_clusters(self):
        #b Produce list of results from valid results
        qs = []
        for m in self.results:
            qs.append(self.results[m])
            pass

        #b Find best centers from results
        handled_results = []
        remaining_qs = qs[:]
        fcs = []
        while len(remaining_qs)>0:
            q = remaining_qs[0]
            v = v_of_q(q)
            fc = self.find_centers(remaining_qs, v, 3.0, 0.005, len(qs)/10, 0.9, 40)
            fcs.append(fc)
            for q in fc[0]:
                handled_results.append(q)
                remaining_qs.remove(q)
                pass
            pass

        #b Sort list of centers
        def fc_cmp(x,y):
            if x[2]/len(x[0])<y[2]/len(y[0]): return -1
            return 1
        fcs.sort(cmp=fc_cmp)
        if True:
            for fc in fcs:
                print fc[2], fc[1], fc[3], fc[4]
                n = 0
                for q in fc[0]:
                    print "  ",q
                    n+=1
                    if n>30:
                        print "  ...."
                        break
                    pass
                pass
            pass

        #b Display list of centers
        agreed_orientations = []
        for fc in fcs:
            tq = quaternion_average(fc[0])
            print "distance",fc[2],"num_in_range",fc[3],"/",len(fc[0]),"iterations left",fc[4], "center (r=",tq.r,",i=",tq.i,",j=",tq.j,",k=",tq.k,")"
            agreed_orientations.append( {"quaternion":tq, "error":fc[2]/len(fc[0])} )
            pass
        return agreed_orientations
    pass

#c c_camera_image
class c_camera_image(object):
    def __init__(self, image_filename, frame_width=22.3, focal_length=35.0, lens_type="rectilinear", orientation=None):
        self.texture = gjslib_c.texture(filename=image_filename)
        self.lp      = gjslib_c.lens_projection(width=1.0,
                                                height=1.0/self.texture.height*self.texture.width,
                                                frame_width=frame_width,
                                                focal_length=focal_length,
                                                lens_type=lens_type)
        if orientation is None:
            orientation = gjslib_c.quaternion(r=1)
            pass
        self.lp.orient(orientation)
        pass
    def orientation(self):
        return self.lp.orientation
    def orientation_of_xy(self,xy):
        return self.lp.orientation_of_xy(xy)
    def orientation_of_xy_list(self, xy_list):
        q_list = []
        for xy in xy_list:
            q_list.append(self.lp.orientation_of_xy(xy))
            pass
        return q_list
    def xy_of_orientation_list(self, q_list):
        xy_list = []
        for q in q_list:
            xy_list.append(self.lp.xy_of_orientation(q))
            pass
        return xy_list

#c c_image_pair_quaternion_match
class c_image_pair_quaternion_match(object):
    def __init__(self, filenames=[]):
        self.camera_images = {}
        for f in filenames:
            self.add_image(f)
            pass
        self.im = c_image_match()
        self.im.max_corners=40
        self.im.max_matches_per_corner=10
        self.to_yuv = c_yuv_from_rgb(extra_parameters={"xsc":2.0,"ysc":2.0,"xc":1.0,"yc":1.0},
                                extra_defines={"EXTRA_VERTEX_UNIFORMS":"uniform float xsc, ysc, xc, yc;",
                                               "GL_POSITION":"vec4(xsc*x+xc,ysc*y+yc,0,1)",
                                               })
        pass
    def orient(self, image, orientation):
        self.camera_images[image].lp.orient(orientation)
        pass
    def xy_of_orientation(self, image, q):
        return self.camera_images[image].lp.xy_of_orientation(q)
    def add_image(self, image_filename="", **kwargs):
        if image_filename not in self.camera_images:
            self.camera_images[image_filename] = c_camera_image(image_filename=image_filename, **kwargs)
            pass
        pass
    def find_overflows(self, images, cxy0, size):
        ci0 = self.camera_images[images[0]]
        ci1 = self.camera_images[images[1]]
        width = ci0.texture.width
        height = ci0.texture.height
        ci0_xy_list = []
        for i in range(4):
            for j in range(20):
                xy = j/10.0-1.0
                xy = [ (xy,-1.0), (1.0,xy), (-xy,1.0), (1.0,-xy) ][i]
                xy = ((cxy0[0] + xy[0]*size/2)*width, (cxy0[1] + xy[1]*size/2)*height)
                ci0_xy_list.append(xy)
                pass
            pass
        q_list      = ci0.orientation_of_xy_list(ci0_xy_list)
        ci1_xy_list = ci1.xy_of_orientation_list(q_list)
        off_edge = [0]*4
        in_bounds = True
        for i in range(4):
            for j in range(20):
                err = None
                for xy in (ci0_xy_list[i*20+j], ci1_xy_list[i*20+j]):
                    xy = (xy[0]/(width/2), xy[1]/(height/2))
                    for k in range(2):
                        if (xy[k]<-1.0):err = -1 - xy[k]
                        if (xy[k]>1.0): err = xy[k] - 1
                        pass
                    if err is None: continue
                    err = abs(err)
                    if err > off_edge[i]:
                        off_edge[i] = err
                        in_bounds = False
                        pass
                    pass
                pass
            pass
        if in_bounds: return None
        return off_edge
    def find_overlap(self, images, cxy0, size, scale=0.9, max_iter=40):
        ci0 = self.camera_images[images[0]]
        ci1 = self.camera_images[images[1]]
        for i in range(max_iter):
            overflow = self.find_overflows(images, cxy0, size)
            #print i, cxy0, size, overflow
            if overflow is None: return (cxy0, size)
            if overflow[0]>0 and overflow[2]>0:   size *= scale
            elif overflow[1]>0 and overflow[3]>0: size *= scale
            else:
                if overflow[0]>0: cxy0=(cxy0[0] + size*(1-scale), cxy0[1])
                if overflow[2]>0: cxy0=(cxy0[0] - size*(1-scale), cxy0[1])
                if overflow[1]>0: cxy0=(cxy0[0], cxy0[1] + size*(1-scale))
                if overflow[3]>0: cxy0=(cxy0[0], cxy0[1] - size*(1-scale))
                pass
            pass
        return None
    def find_matches(self, images, cxy0, size):
        global img_png_n
        # 'size' maps to frame_width;
        # fov = 2atan2(frame_width/2focal_length) = 2atan2(size/2)
        # hence size = frame_width/focal_length
        # hence focal_length = frame_width/size
        focal_length = 36.0 / size
        if img_png_n>0:focal_length=300.0
        ci0 = self.camera_images[images[0]]
        ci1 = self.camera_images[images[1]]

        src_img_lp_to = gjslib_c.lens_projection(width=1.0, height=1.0, frame_width=36.0, focal_length=focal_length, lens_type="rectilinear")
        dst_img_lp_to = gjslib_c.lens_projection(width=1.0, height=1.0, frame_width=36.0, focal_length=focal_length, lens_type="rectilinear")

        # Currently we can change ci0 orientation and src_to_orientation works great with world_cxy0_q
        # (but presumably not with ci0.orientation() * world_cxy0_q...)
        # The dest projection camera needs to point at world_cxy0_q relative to the destination image
        # as the destination image is accessed 'destination image local'
        # Not sure I buy this logic actually...
        print "Centering on image 0",cxy0, (cxy0[0]+0.5)*5184, (cxy0[1]+0.5)*3456
        world_cxy0_q = ci0.orientation_of_xy(cxy0)

        src_to_orientation = world_cxy0_q
        dst_to_orientation = world_cxy0_q

        dst_img_lp_to.orient(dst_to_orientation)
        src_img_lp_to.orient(src_to_orientation)

        #b Find matches
        self.to_yuv.set_parameters( {"ysc":2.0, "yc":-1.0, "xsc":2.0, "xc":-1.0} )
        self.to_yuv.set_projections(projections=(ci0.lp,src_img_lp_to), num_x_divisions=20, num_y_divisions=20)
        self.to_yuv.execute((ci0.texture,tb[0]))
        self.to_yuv.set_projections(projections=(ci1.lp,dst_img_lp_to), num_x_divisions=20, num_y_divisions=20)
        self.to_yuv.execute((ci1.texture,tb[1]))
        matches = self.im.get_matches(tb)

        save_as_png(tb[0],"a%d.png"%img_png_n)
        save_as_png(tb[1],"b%d.png"%img_png_n)
        img_png_n+=1

        #b Matches of stuff
        class c_mappings(object):
            def __init__(self, src_xy, src_q):
                self.src_xy = src_xy
                self.src_q = src_q
                self.matches = {}
                self.tgt_qs = []
                self.tgt_q_mappings = {}
                pass
            def add_match(self, tgt_xy, tgt_q, fft_rot, fft_power):
                self.tgt_qs.append(tgt_q)
                self.tgt_q_mappings[tgt_q] = []
                self.matches[tgt_q] = (tgt_xy, tgt_q, fft_rot, fft_power)
                pass
            def add_tgt_mapping(self, tgt_q, src_q1, tgt_q1, qm):
                if tgt_q not in self.tgt_qs:
                    raise Exception, "Unexpected add_tgt_mapping for tgt quaternion that is not part of the source"
                self.tgt_q_mappings[tgt_q].append( (src_q1, tgt_q1, qm.src_from_tgt_orient) )
                pass
            pass

        mappings_by_src_q = {}
        for m in matches:
            mxy = (float(m[0])/tb[0].width-0.5, float(m[1])/tb[0].height-0.5)
            src_q = src_img_lp_to.orientation_of_xy(mxy)
            mappings_by_src_q[src_q] = c_mappings(mxy, src_q)
            for mm in matches[m]:
                tgt_xy = ( float(mm[0])/tb[1].width-0.5, float(mm[1])/tb[1].height-0.5 )
                fft_rot = 180/math.pi*math.atan2(mm[3],mm[4])
                tgt_q = dst_img_lp_to.orientation_of_xy(tgt_xy)
                mappings_by_src_q[src_q].add_match(tgt_xy, tgt_q, fft_rot, mm[2])
                pass
            pass

        #b Build results as dictionary of quaternion matches
        for src_q0 in mappings_by_src_q:
            for src_q1 in mappings_by_src_q:
                if src_q0 == src_q1: continue
                for tgt_q0 in mappings_by_src_q[src_q0].tgt_qs:
                    for tgt_q1 in mappings_by_src_q[src_q1].tgt_qs:
                        qm = c_quaternion_match.test_add(src_qs=(src_q0,src_q1),
                                                         tgt_qs=(tgt_q0,tgt_q1),
                                                         max_angle_diff=0.3)
                        if qm is not None:
                            #rq = qm.src_from_tgt_orient
                            #print "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k)
                            mappings_by_src_q[src_q0].add_tgt_mapping(tgt_q0, src_q1, tgt_q1, qm)
                            pass
                        pass
                    pass
                pass
            pass

        self.mappings_by_src_q = mappings_by_src_q
        return (mappings_by_src_q, world_cxy0_q, dst_to_orientation)
    #b Find 'best other target matches' for each source match
    class c_best_match(object):
        def __init__(self, src_q0, src_q1, tgt_q0, tgt_q1, src_from_tgt_q):
            self.min_distance = None
            self.max_distance = None
            self.src_from_tgt_q = src_from_tgt_q
            self.mappings = {src_q0:(0.0,tgt_q0), src_q1:(0.0,tgt_q1)}
            pass
        def add_match(self, src_q, tgt_q, distance):
            self.mappings[src_q] = (distance, tgt_q)
            if (self.max_distance is None) or (self.max_distance<distance):
                self.max_distance = distance
                pass
            pass
        pass
    #b Find 'best other target matches' for each source match
    def find_best_matches_within_distance(self, mappings_by_src_q, src_q0, src_q1, tgt_q0, tgt_q1, src_from_tgt_q, min_distance, min_used):
        matches_used = self.c_best_match(src_q0, src_q1, tgt_q0, tgt_q1, src_from_tgt_q)
        max_d = None
        for src_qx in mappings_by_src_q:
            if src_qx in matches_used.mappings: continue
            min_d = (None, None)
            for tgt_qx in mappings_by_src_q[src_qx].tgt_qs:
                d = c_vector.vector_diff(v_of_q(src_qx), v_of_q(src_from_tgt_q*tgt_qx))
                d = c_vector.vector_length(d)
                if (min_d[0] is None) or (min_d[0]>d):
                    min_d = (d, tgt_qx)
                    pass
                pass
            if min_d[0] is None: continue
            if min_d[0]>min_distance: continue
            matches_used.add_match(src_qx, min_d[1], min_d[0])
            pass
        if len(matches_used.mappings)<min_used: return None
        if matches_used.max_distance is None: return None
        return matches_used
    #f find_best_target_matches
    def find_best_target_matches(self, mappings_by_src_q, min_used_factor=0.5):
        best_other_target_matches = []
        global_min_d = 1000
        min_used = len(mappings_by_src_q)*min_used_factor
        for src_q0 in mappings_by_src_q:
            for tgt_q0 in mappings_by_src_q[src_q0].tgt_qs:
                for (src_q1, tgt_q1, src_from_tgt_q) in mappings_by_src_q[src_q0].tgt_q_mappings[tgt_q0]:
                    bm = self.find_best_matches_within_distance(mappings_by_src_q, src_q0, src_q1, tgt_q0, tgt_q1, src_from_tgt_q, min_distance=global_min_d*1.2, min_used=min_used)
                    if bm is None: continue
                    if (bm.max_distance < global_min_d):
                        global_min_d = bm.max_distance
                        pass
                    best_other_target_matches.append(bm)
                    pass
                pass
            pass
        return (best_other_target_matches, global_min_d)

#a Testy functions
#f test_to_yuv
def test_to_yuv():
    to_yuv = c_yuv_from_rgb(extra_parameters={"xsc":2.0,"ysc":2.0,"xc":1.0,"yc":1.0},
                            extra_defines={"EXTRA_VERTEX_UNIFORMS":"uniform float xsc, ysc, xc, yc;",
                                           "GL_POSITION":"vec4(ysc*y+yc,xsc*x+xc,0,1)",
                                           })
    img = gjslib_c.texture(filename='images/IMG_2162.JPG')
    to_yuv.f.parameter("ysc",4.0)
    to_yuv.f.parameter("xsc",4.0)
    to_yuv.f.parameter("yc",-2.0)
    to_yuv.f.parameter("xc",-2.0)
    to_yuv.execute((img,tb[4]))
    save_as_png(tb[4],"img_rgb2.png")
    pass

#f test_alu
def test_alu():
    print "ALU tests"

    alu_test( [ ((2,2,0), "vec4(0.5)", "test_constant_50.png"),
                ((2,2,1), "vec4(0.8)", "test_constant_80.png"),
                ((0,1,2), "src_a*src_b", "test_constant_40.png"),
                ] )

    alu_test( [ ((2,2,0), "vec4(x*y)",    "test_xy.png"),
                ((2,2,1), "vec4((1-x)*y)",  "test_x1y.png"),
                ((0,1,2), "vec4(1-4*src_a.r*src_b.r)", "test_xymult.png"),
                ] )

    alu_test( [ ((2,2,0), "vec4(abs(sin(200*x*y)*sin(200*(1-x)*y)))",    "test_sin_xy.png"),
                ] )

#f test_gauss
def test_gauss():
    print "Gauss filter and find test"
    gfx = c_gauss_filter_x()
    gfy = c_gauss_filter_y()
    gfx.execute((tb[0],tb[1]))
    gfy.execute((tb[1],tb[2]))
    save_as_png(tb[2],"test_gauss_sin_xy.png")

    alu_test( [ ((0,2,3),"vec4(30*abs(src_a.r-src_b.r))","test_gauss_sin_xy_diff.png"),
                ] )

    circle_dft = c_circle_dft_filter(extra_defines={"SINGLE_COMPONENT":4, "COMPONENT_SCALE":4})
    circle_dft.execute((tb[2],tb[3]))
    save_as_png(tb[3],"test_gauss_sin_xy_dft.png")

    f = gjslib_c.filter(filter='find:a(10)')
    f.compile()
    f.textures((tb[3],))
    f.parameter("minimum",0.87)
    f.execute()
    print f.num_points
    print f.points

#f test_dft_images
def test_dft_images():
    print "DFT images"

    img = gjslib_c.texture(filename='images/IMG_2162.JPG')
    to_yuv = c_yuv_from_rgb(extra_defines={"INTENSITY_XSCALE":"%f"%(img.height/float(img.width)),
                                           "INTENSITY_YSCALE":"1.0",
                                           "INTENSITY_YOFS":"0.0",
                                           "INTENSITY_XOFS":"0.0",})
    to_yuv.execute((img,tb[4]))
    save_as_png(tb[4],"img_rgb.png")

    for (i,sc) in [(0,1), (1,6), (2,5), (3,3.5), (4,2), (5,2), (6,2)]:
        if False:
                circle_dft = c_circle_dft_filter(extra_defines={"DFT_CIRCLE_RADIUS":4+4*i,
                                                                "SINGLE_COMPONENT":2,
                                                                "COMPONENT_SCALE":4})
                pass
        else:
                circle_dft = c_circle_dft_filter(extra_defines={"DFT_CIRCLE_RADIUS":8,
                                                        "SINGLE_COMPONENT":i,
                                                        "COMPONENT_SCALE":sc})
                pass
        circle_dft.execute((tb[4],tb[5]))
        save_as_png(tb[5],"img_dft_%d.png"%i)
    pass

#f test_diff_image_and_match
def test_diff_image_and_match():
    print "Diff images and map matches"

    quaternion      = gjslib_c.quaternion
    lp_35 = gjslib_c.lens_projection(width=1024.0*5184/3456, frame_width=22.3, focal_length=35.0, lens_type="rectilinear")
    lp_35.orient(quaternion().lookat((0,0,1),(1,0,0)))

    to_yuv = c_yuv_from_rgb(extra_parameters={"xsc":2.0,"ysc":2.0,"xc":1.0,"yc":1.0},
                            extra_defines={"EXTRA_VERTEX_UNIFORMS":"uniform float xsc, ysc, xc, yc;",
                                           "GL_POSITION":"vec4(xsc*x+xc,ysc*y+yc,0,1)",
                                           })
    im = c_image_match()

    imgs = ( gjslib_c.texture(filename='images/IMG_1900.JPG'),
             gjslib_c.texture(filename='images/IMG_1901.JPG') )

    ar = float(imgs[0].width)/imgs[0].height
    to_yuv.set_parameters( {"ysc":2.0, "yc":-1.0, "xsc":2.0*ar, "xc":-1.0*ar} )
    to_yuv.execute((imgs[0],tb[0]))
    to_yuv.execute((imgs[1],tb[1]))
    ic = gjslib_c.image_correlator()
    print "points ",ic.points,"max corners",im.max_corners
    matches = im.get_matches(tb)
    for m in matches:
        print "Match ",m,matches[m]
        ic.add_point(str(m),m[0],m[1])
        n=0
        for mm in matches[m]:
            ic.add_mapping(str(m),"map%s.%d"%(str(m),n),mm[0],mm[1],mm[2],mm[3],mm[4])
            n+=1
            pass
        pass
    print "points ",ic.points
    for pt in ic.points:
        mappings = ic.mappings(pt)
        print "  mapping ",pt,mappings
        for m in mappings:
            print "    ",m,ic.get_mapping(pt,m)    
        pass
    for pt in ic.points:
        print "Num propositions before creation for", pt,  ic.propositions(pt)
    ic.create_propositions(min_strength=0)
    for pt in ic.points:
        n = ic.propositions(pt)
        print "Num propositions after creation for", pt, n
        for i in range(n):
            print "   Proposition",i,ic.get_proposition(pt,i)
            pass
        pass
    best_mapping=ic.find_best_mapping()
    print "Best mapping", best_mapping
    (dx,dy,rotation,scale) = best_mapping[1]
    #(dx,dy,rotation,scale) = (156.4246678601715, -63.62960520116849, 0.22949442458934716, 0.9982186254612156)
    cosang = math.cos(rotation)
    sinang = math.sin(rotation)
    for m in matches:
        (x,y) = m[:2]
        tgt_x = dx+(x*cosang-y*sinang)*scale
        tgt_y = dy+(y*cosang+x*sinang)*scale
        print m[:2],"maps to",(tgt_x,tgt_y)
        pass
    pass

#c c_vector
class c_vector(object):
    #f vector_diff
    @staticmethod
    def vector_diff(v0,v1):
        r = []
        for i in range(len(v0)):
            r.append(v0[i]-v1[i])
            pass
        return tuple(r)
    #f dot_product
    @staticmethod
    def dot_product(p0,p1):
        r = 0
        for i in range(len(p0)):
            r += p0[i]*p1[i]
            pass
        return r
    #f vector_product
    @staticmethod
    def vector_product(p0,p1):
        r = ( p0[1]*p1[2] - p0[2]*p1[1],
              p0[2]*p1[0] - p0[0]*p1[2],
              p0[0]*p1[1] - p0[1]*p1[0])
        return r
    #f vector_length
    @staticmethod
    def vector_length(p):
        l=0
        for d in p: l+=d*d
        return math.sqrt(l)
    #f vector_normalize
    @staticmethod
    def vector_normalize(p):
        l=c_vector.vector_length(p)
        if abs(l)<1E-10:l=1.0
        r=[]
        for d in p: r.append(d/l)
        return tuple(r)
    #f axis_angle_from_v0_to_v1
    @staticmethod
    def axis_angle_from_v0_to_v1(v0,v1):
        axis = c_vector.vector_product(v0, v1)
        angle = math.atan2(c_vector.vector_length(axis),c_vector.dot_product(v0,v1))
        axis  = c_vector.vector_normalize(axis)
        return (axis,angle)
    #f axis_angle_of_quaternion_diff
    @staticmethod
    def axis_angle_of_quaternion_diff(q0,q1,pt=(0,0,1)):
        return c_vector.axis_angle_from_v0_to_v1(q0.rotate_vector(pt), q1.rotate_vector(pt))

#f validate_buckets
def validate_buckets(results, nbkt=500, fraction=0.01):
    nres = len(results)
    bkts = []
    for i in range(3):
        bkts.append([0]*nbkt)
        pass
    def bkts_of_q(q,nbkt):
        r = []
        qt = v_of_q(q)
        for i in range(3):
            c = qt[i] # -1.0 to 1.0
            b = int((c+1.0)/2.000001*nbkt) # 0 to nbkt
            r.append(b)
            pass
        return r
    for m in results:
        q = results[m]
        qb = bkts_of_q(q,nbkt)
        for i in range(3):
            bkts[i][qb[i]] += 1
        pass
    bkts_small_pct = []
    for i in range(3):
        bkts_small_pct.append([])
        for j in range(nbkt):
            if bkts[i][j] >= (nres*fraction):
                bkts_small_pct[-1].append(j)
                pass
            pass
        pass
    valid_results = {}
    for m in results:
        q = results[m]
        qb = bkts_of_q(q,nbkt)
        valid = True
        for i in range(3):
            if ((qb[i] not in bkts_small_pct[i]) and
                ((qb[i]-1) not in bkts_small_pct[i]) and
                ((qb[i]+1) not in bkts_small_pct[i])):
                valid = False
            pass
        if valid:
            valid_results[m] = q    
        pass
    return valid_results

#f test_diff_image_quaternion
def test_diff_image_quaternion():
    #b Init
    print "Diff images with quaternions"

    quaternion      = gjslib_c.quaternion

    src_orientation = quaternion().from_euler(yaw=0,degrees=True) * quaternion().from_euler(pitch=-30,degrees=True)
    dst_orientation = quaternion().lookat((0,2,1),(0,1,0))
    #1901
    dst_orientation = quaternion(r=0.950655, i=-0.122744, j=-0.245672, k=-0.144343)
    src_orientation = quaternion(r=0.957717, i=0.023461, j=-0.264079, k=-0.111759)

    dst_orientation = quaternion(r=0.942618, i=0.038782, j=-0.265809, k=-0.198256)
    # This one is best...
    dst_orientation = quaternion(r=0.942579, i=0.039081, j=-0.265648, k=-0.198577)
    # Evening...
    dst_orientation = quaternion(r= 0.942003915584 ,i= 0.0393731632942 ,j= -0.265974639344 ,k= -0.200837915398 )
    dst_orientation = quaternion(r= 0.941906014717 ,i= 0.0389807399661 ,j= -0.266129774404 ,k= -0.201167851624 )
    dst_orientation = quaternion().lookat((0,2,1),(0,1,0))
    dst_orientation = quaternion(r= 0.943114593009 ,i= 0.036678893399 ,j= -0.266698808114 ,k= -0.195092975228 )
    dst_orientation = src_orientation.copy()

    focal_length = 35.0
    focal_length = 20.0
    src_lp_35 = gjslib_c.lens_projection(width=1024.0, frame_width=22.3*3456/5184, focal_length=focal_length, lens_type="rectilinear")
    dst_lp_35 = gjslib_c.lens_projection(width=1024.0, frame_width=22.3*3456/5184, focal_length=focal_length, lens_type="rectilinear")

    src_lp_35.orient(src_orientation)
    dst_lp_35.orient(dst_orientation)

    #b Find matches
    if True:
        to_yuv = c_yuv_from_rgb(extra_parameters={"xsc":2.0,"ysc":2.0,"xc":1.0,"yc":1.0},
                                extra_defines={"EXTRA_VERTEX_UNIFORMS":"uniform float xsc, ysc, xc, yc;",
                                               "GL_POSITION":"vec4(xsc*x+xc,ysc*y+yc,0,1)",
                                               })
        im = c_image_match()
        im.max_corners=15
        im.max_matches_per_corner=8

        imgs = ( gjslib_c.texture(filename='images/IMG_1901.JPG'),
                 gjslib_c.texture(filename='images/IMG_1902.JPG') )
        imgs = ( gjslib_c.texture(filename='images/IMG_2180.JPG'),
                 gjslib_c.texture(filename='images/IMG_2181.JPG') )

        ar = float(imgs[0].width)/imgs[0].height
        to_yuv.set_parameters( {"ysc":2.0, "yc":-1.0, "xsc":2.0*ar, "xc":-1.0*ar} )
        to_yuv.execute((imgs[0],tb[0]))
        to_yuv.execute((imgs[1],tb[1]))
        matches = im.get_matches(tb)
        print matches
        save_as_png(tb[0],"a.png")
        pass

    #b Matches of stuff
    # Presumably for any two points on source image there is a great circle rotation to go from one to the other
    # The same rotation must match that for the corresponding target positions
    # So, what is the great circle rotation to go from one position to another?
    # We know for each point on an image a quaternion 'q' that maps (0,0,1) to the location in 'image sphere space'
    # Hence we have two points in 'image sphere space' p0 and p1, where pn = qn.(0,0,1).qn'
    # What quaternion maps p0 to p1?
    # The axis of rotation is in direction; p0 x p1; and cos(rot) = p0.p1 (and sin(rot)=|p0 x p1|)
    # Note that p0.p1 = p0 p1 = q0.(0,0,1).q0'.q1'.(0,0,1).q1
    # If q0 = w0,x0,y0,z0, and q1 is w1,x1,y1,z1 then p0.p1 = 4(z0x0-w0y0)(z1x1-w1y1) + 4(w0x0+y0z0)(w1x1+y1z1) + (w0w0-x0x0-y0y0+z0z0)(w1w1-x1x1-y1y1+z1z1)
    # Now if the great circle rotation is represented as a quaternion then its w is the cos of the angle of rotation, i.e. p0.p1
    # Now note also that p0 = q0(0,0,1)
    # Hence q0'(p0) = (0,0,1)
    # Hence q1(q0'(p0)) = p1
    # Hence q1.q0' is the mapping from p0 to p1
    # Now q1.q0' = (w1w0, -w1x0, -w1y0, -w1z0) + i(x1w0, -x1x0, -x1y0, -x1z0) + j(y1w0, -y1x0, -y1y0, -y1z0) + k(z1w0, -z1x0, -z1y0, -z1z0)
    #            = (w1w0, -w1x0, -w1y0, -w1z0) +  (x1x0,  x1w0,  x1z0, -x1y0) +  (y1y0, -y1z0,  y1w0,  y1x0) +  (z1z0,  z1y0, -z1x0,  z1w0)
    #            = (w1w0+x0x1+y0y1+z0z1, x1w0-w1x0+z1y0-y1z0, y1w0-w1y0+x1z0-z1x0, w0z1-w1z0+z0x1-z1x0)
    data = {}
    for m in matches:
        mxy = (m[0]-tb[0].width/2,m[1]-tb[0].height/2)
        print "Match ", m, matches[m],mxy
        src_q = src_lp_35.orientation_of_xy(mxy)
        data[src_q] = (mxy,[])
        for mm in matches[m]:
            mmxy = (mm[0]-tb[1].width/2,mm[1]-tb[1].height/2)
            tgt_q = dst_lp_35.orientation_of_xy(mmxy)
            fft_rot = 180/math.pi*math.atan2(mm[3],mm[4])
            data[src_q][1].append( (tgt_q, fft_rot, mm[2], mmxy) )
            pass
        pass
    #b Show matches
    if False:
        for src_q in data:
            (src_xy, matches) = data[src_q]    
            for (tgt_q, fft_rot, fft_pwr, tgt_xy) in matches:
                print src_xy, "=>", tgt_xy
                pass
            pass
        pass
    #b Build results as dictionary of quaternion matches
    results = {}
    for src_q0 in data:
        for src_q1 in data:
            if src_q0 == src_q1: continue
            for t0 in data[src_q0][1]:
                for t1 in data[src_q1][1]:
                    if abs(t0[0]-t1[0])<1E-8: continue
                    tgt_q0 = t0[0]
                    tgt_q1 = t1[0]
                    qm = c_quaternion_match.test_add(src_qs=(src_q0,src_q1),
                                                     tgt_qs=(tgt_q0,tgt_q1),
                                                     max_angle_diff=0.3)
                    if qm is not None:
                        results[(data[src_q0][0], data[src_q1][0], t0[3], t1[3])] = qm.src_from_tgt_orient * dst_orientation
                        pass
                    pass
                pass
            pass
        pass

    #b Show results
    if False:
        for m in results:
            (s0,s1,t0,t1) = m
            print s0,s1,t0,t1,results[m]
            pass
        pass

    #b Bucket up quaternions to find numerous near-matches
    valid_results = validate_buckets(results)
    print valid_results

    #b Do clusters
    qc = c_quaternion_cluster(valid_results)
    print qc.find_clusters()
    pass

#f test_diff_image_quaternion_2
def test_diff_image_quaternion_2():
    #b Init
    print "Diff images with quaternions (two)"
    imgs = ( gjslib_c.texture(filename='images/IMG_1900.JPG'),
             gjslib_c.texture(filename='images/IMG_1901.JPG') )


    quaternion      = gjslib_c.quaternion

    src_orientation = quaternion(r=1)
    dst_orientation = quaternion(r=1)

    src_img_lp_35 = gjslib_c.lens_projection(width=1024.0, height=1024.0/3456.0*5184, frame_width=22.3, focal_length=35.0, lens_type="rectilinear")
    dst_img_lp_35 = gjslib_c.lens_projection(width=1024.0, height=1024.0/3456.0*5184, frame_width=22.3, focal_length=35.0, lens_type="rectilinear")

    src_img_lp_35.orient(src_orientation)
    dst_orientation = src_orientation * quaternion(r=0.993334,i=-0.006355,j=-0.007261,k=-0.114871) * quaternion(r=0.999925,i=0.006125,j=0.010561,k=-0.000094) * quaternion(r=0.999996,i=-0.002278,j=0.001577,k=0.000149)
    dst_img_lp_35.orient(dst_orientation)

    src_img_lp_to = gjslib_c.lens_projection(width=1024.0, frame_width=36.0, focal_length=250.0, lens_type="rectilinear")
    dst_img_lp_to = gjslib_c.lens_projection(width=1024.0, frame_width=36.0, focal_length=250.0, lens_type="rectilinear")
    src_to_orientation = src_img_lp_35.orientation_of_xy((-0.08,0.25))
    #src_to_orientation = src_img_lp_35.orientation_of_xy((-0.01,0.01))
    dst_to_orientation = dst_img_lp_35.orientation_of_xy((-0.16,0.1))
    dst_to_orientation = dst_orientation * src_to_orientation

    #src_to_orientation = src_img_lp_35.orientation_of_xy((0,0))
    #dst_to_orientation = dst_img_lp_35.orientation_of_xy((0,0))

    src_img_lp_to.orient(src_to_orientation)
    #dst_to_orientation = quaternion(r=0.701862,i=-0.118005,j=-0.043319,k=-0.701133) * src_to_orientation
    #dst_to_orientation = src_to_orientation * quaternion(r=0.993139,i=-0.001478,j=0.003958,k=-0.116867) * dst_to_orientation
    dst_img_lp_to.orient(dst_to_orientation)

    #b Find matches
    if True:
        to_yuv = c_yuv_from_rgb(extra_parameters={"xsc":2.0,"ysc":2.0,"xc":1.0,"yc":1.0},
                                extra_defines={"EXTRA_VERTEX_UNIFORMS":"uniform float xsc, ysc, xc, yc;",
                                               "GL_POSITION":"vec4(xsc*x+xc,ysc*y+yc,0,1)",
                                               })
        im = c_image_match()
        im.max_corners=15
        im.max_matches_per_corner=8
        im.max_corners=40
        im.max_matches_per_corner=6

        to_yuv.set_parameters( {"ysc":2.0, "yc":-1.0, "xsc":2.0, "xc":-1.0} )
        to_yuv.set_projections(projections=(src_img_lp_35,src_img_lp_to), num_x_divisions=20, num_y_divisions=20)
        to_yuv.execute((imgs[0],tb[0]))
        to_yuv.set_projections(projections=(dst_img_lp_35,dst_img_lp_to), num_x_divisions=20, num_y_divisions=20)
        to_yuv.execute((imgs[1],tb[1]))
        matches = im.get_matches(tb)
        print matches
        save_as_png(tb[0],"a.png")
        save_as_png(tb[1],"b.png")
        pass

    #b Matches of stuff
    data = {}
    match_qs = {}
    for m in matches:
        mxy = (m[0]-tb[0].width/2,m[1]-tb[0].height/2)
        print "Match ", m, matches[m], mxy
        src_q = src_img_lp_to.orientation_of_xy(mxy)
        data[src_q] = (mxy,[])
        match_qs[src_q] = []
        for mm in matches[m]:
            mmxy = (mm[0]-tb[1].width/2,mm[1]-tb[1].height/2)
            tgt_q = dst_img_lp_to.orientation_of_xy(mmxy)
            fft_rot = 180/math.pi*math.atan2(mm[3],mm[4])
            data[src_q][1].append( (tgt_q, fft_rot, mm[2], mmxy) )
            match_qs[src_q].append(tgt_q)
            pass
        pass

    #b Build results as dictionary of quaternion matches
    results = {}
    for src_q0 in data:
        for src_q1 in data:
            if src_q0 == src_q1: continue
            for tgt_q0 in match_qs[src_q0]:
                if (src_q0, tgt_q0) not in results:
                    results[(src_q0, tgt_q0)] = []
                    pass
                for tgt_q1 in match_qs[src_q1]:
                    qm = c_quaternion_match.test_add(src_qs=(src_q0,src_q1),
                                                     tgt_qs=(tgt_q0,tgt_q1),
                                                     max_angle_diff=0.3)
                    if qm is not None:
                        results[(src_q0, src_q1, tgt_q0, tgt_q1)] = qm.src_from_tgt_orient
                        results[(src_q0, tgt_q0)].append( (src_q1, tgt_q1) )
                        pass
                    pass
                pass
            pass
        pass

    #b Find 'best other target matches' for each source match
    def blah(match_qs, src_q0, src_q1, tgt_q0, tgt_q1, src_from_tgt_q, min_distance=0.1):
        matches_used = {src_q0:(0.0,tgt_q0), src_q1:(0.0,tgt_q1)}
        max_d = None
        for src_qx in match_qs:
            if src_qx in matches_used: continue
            min_d = (None, None)
            for tgt_qx in match_qs[src_qx]:
                d = c_vector.vector_diff(v_of_q(src_qx), v_of_q(src_from_tgt_q*tgt_qx))
                d = c_vector.vector_length(d)
                if (min_d[0] is None) or (min_d[0]>d):
                    min_d = (d, tgt_qx)
                    pass
                pass
            if min_d[0] is None: continue
            if min_d[0]>min_distance: continue
            matches_used[src_qx] = min_d
            if (max_d is None) or (max_d<min_d[0]):
                max_d = min_d[0]
            pass
        return (min_d, max_d, matches_used)

    best_other_target_matches = {}
    global_min_d = 1000
    min_used = len(data)/2
    for src_q0 in match_qs:
        for tgt_q0 in match_qs[src_q0]:
            match = (src_q0, tgt_q0)
            if len(results[match])==0:
                continue
            for (src_q1, tgt_q1) in results[match]:
                src_from_tgt_q = results[(src_q0, src_q1, tgt_q0, tgt_q1)]
                (min_d, max_d, matches_used) = blah(match_qs, src_q0, src_q1, tgt_q0, tgt_q1, src_from_tgt_q)
                if max_d is None: continue
                if (max_d < global_min_d) and (len(matches_used)>=min_used):
                    global_min_d = max_d
                    pass
                matches_used["max"] = max_d
                best_other_target_matches[(src_q0, src_q1, tgt_q0, tgt_q1)] = matches_used
                pass
            pass
        pass

    #b Do clusters
    print len(data), global_min_d
    for mapping in best_other_target_matches:
        (src_q0, src_q1, tgt_q0, tgt_q1) = mapping
        #if src_q0 is not data.keys()[0]:continue
        match = best_other_target_matches[mapping]
        if match["max"] > 1.1*global_min_d: continue
        if len(match)<min_used-1: continue
        rq = results[mapping]
        print match["max"], "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(match)
        for sq in match:
            if sq == "max": continue
            if sq is src_q0: continue
            if sq is src_q1: continue
            tgt_qx = match[sq][1]
            txy = "None"
            for t in data[sq][1]:
                if t[0] is tgt_qx:
                    txy = str(t[3])
                    pass
                pass
            print "%6.3f:%s:%s"%(match[sq][0],str(data[sq][0]),txy),
            pass
        print
        pass
    pass

#f test_diff_image_quaternion_3
def test_diff_image_quaternion_3():
    #b Init
    images = ('images/IMG_1900.JPG', 'images/IMG_1901.JPG')
    focal_length = 35.0
    if True:
        images = ('images/IMG_2174.JPG', 'images/IMG_2173.JPG')
        focal_length = 20.0
        pass
    ipqm = c_image_pair_quaternion_match()
    ipqm.add_image(image_filename=images[0], orientation=gjslib_c.quaternion(r=1), focal_length=focal_length )
    ipqm.add_image(image_filename=images[1], orientation=gjslib_c.quaternion(r=1), focal_length=focal_length )

    print "Diff images with quaternions (three)"
    (cxy, size) = ((0,0),0.5)
    region = ipqm.find_overlap(images, cxy, size)
    print region

    (mappings_by_src_q, src_to_orientation, dst_to_orientation) = ipqm.find_matches( (images[0], images[1]), cxy, size )
    (best_other_target_matches, global_min_d) = ipqm.find_best_target_matches(mappings_by_src_q, min_used_factor=0.3) #GJST was 0.5

    #b Do clusters
    def cmp_matches(x,y):
        if x.max_distance/len(x.mappings)<y.max_distance/len(y.mappings): return -1
        return 1
    best_other_target_matches.sort(cmp=cmp_matches)
    print "Best matches for whole image"
    for mapping in best_other_target_matches:
        if mapping.max_distance > 1.1*global_min_d: continue
        rq = mapping.src_from_tgt_q
        print mapping.max_distance, "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
        pass

    chosen_mapping = best_other_target_matches[1]
    ipqm.orient(images[1], chosen_mapping.src_from_tgt_q)
    centers = []
    for src_q in chosen_mapping.mappings:
        xy = ipqm.xy_of_orientation(images[0],src_q)
        print mappings_by_src_q[src_q].src_xy, xy, (xy[0]+0.5)*5184,(xy[1]+0.5)*3456
        rq = src_q
        print "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k)
        #print ipqm.camera_images[images[0]].lp.frame_width,ipqm.camera_images[images[0]].lp.focal_length
        #print ipqm.camera_images[images[0]].lp.xy_of_orientation(src_q)
        #xy = (xy[0]/5184.0, xy[1]/3456.0)
        print "src_xy",(mappings_by_src_q[src_q].src_xy[0]+0.5)*1024, (mappings_by_src_q[src_q].src_xy[1]+0.5)*1024
        centers.append(xy)
        pass

    delta_matches = {}
    for cxy in centers:#[]:
        print "Trying",cxy
        region = ipqm.find_overlap((images[0], images[1]), cxy, 0.1)
        print "Region",region
        if region is None:
            continue
        (cxy, size) = region
        (mappings_by_src_q, src_to_orientation, dst_to_orientation) = ipqm.find_matches( (images[0], images[1]), cxy, size )
        (best_other_target_matches, global_min_d) = ipqm.find_best_target_matches(mappings_by_src_q, min_used_factor=0.8)
        if len(best_other_target_matches)==0:
            print "No best matches"
            continue

        #b Do clusters
        best_other_target_matches.sort(cmp=cmp_matches)
        mapping = best_other_target_matches[0]
        delta_matches[cxy] = mapping
        # mapping.src_from_tgt_q is a mapping that goes from project_tq to projected_sq
        # The final mapping we need is base_tq to base_sq
        # Center of both images in space is base_sq * src_ry_of_xy(cxy)
        # the image projection does subimage(xy) = subimage(q) = image(q) = world(q)*~image_orientation
        # project_tq = base_tq * (base_sq * src_ry_of_xy(cxy))
        # project_sq = base_sq * src_ry_of_xy(cxy)
        if False:
            rq = mapping.src_from_tgt_q
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = mapping.src_from_tgt_q * ~dst_to_orientation
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "q.d (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = mapping.src_from_tgt_q * dst_to_orientation
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = ~dst_to_orientation *mapping.src_from_tgt_q
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "q.d (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = dst_to_orientation *mapping.src_from_tgt_q
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "q.~d (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = ~src_to_orientation * mapping.src_from_tgt_q * dst_to_orientation
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "ns.q.d (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = src_to_orientation * mapping.src_from_tgt_q * ~dst_to_orientation
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "s.q.nd (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = ~dst_to_orientation * mapping.src_from_tgt_q * src_to_orientation
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "nd.q.s (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            rq = dst_to_orientation * mapping.src_from_tgt_q * ~src_to_orientation
            rq = rq * chosen_mapping.src_from_tgt_q
            print mapping.max_distance, "d.q.ns (r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
            pass
        mapping.src_from_tgt_q = mapping.src_from_tgt_q * chosen_mapping.src_from_tgt_q
        rq = mapping.src_from_tgt_q
        print mapping.max_distance, "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
        pass

    ordered_matches = []
    for cxy in delta_matches:
        ordered_matches.append(delta_matches[cxy])
        pass
    ordered_matches.sort(cmp=cmp_matches)
    for mapping in ordered_matches:
        rq = mapping.src_from_tgt_q
        print mapping.max_distance, "(r=%f,i=%f,j=%f,k=%f)"%(rq.r,rq.i,rq.j,rq.k),len(mapping.mappings)
        pass
    ordered_matches = ordered_matches[0:len(ordered_matches)/2+1]
    orientations = []
    for mapping in ordered_matches:
        orientations.append(mapping.src_from_tgt_q)
        pass
    dq = quaternion_average(orientations)
    print "quaternion(r=%f,i=%f,j=%f,k=%f)"%(dq.r,dq.i,dq.j,dq.k),len(orientations),len(delta_matches)
    pass


#f test_diff_image
def test_diff_image():
    print "Diff images"

    imgs = ( gjslib_c.texture(filename='images/IMG_1900.JPG'),
             gjslib_c.texture(filename='images/IMG_1901_r10.JPG') )

    to_yuv = c_yuv_from_rgb(extra_parameters={"xsc":2.0,"ysc":2.0,"xc":1.0,"yc":1.0},
                            extra_defines={"EXTRA_VERTEX_UNIFORMS":"uniform float xsc, ysc, xc, yc;",
                                           "GL_POSITION":"vec4(xsc*x+xc,ysc*y+yc,0,1)",
                                           })
    copy_img = c_alu_filter(extra_defines={"OP":"src_a"})
    equalize = c_windowed_equalization_filter()
    harris = c_harris_filter()
    find_corners = c_find_filter(extra_parameters={"min_distance":10.0, "max_elements":20})
    find_matches = c_find_filter(extra_parameters={"min_distance":2.5, "minimum":0.1, "max_elements":100})
    circle_dft = c_circle_dft_filter(extra_defines={"DFT_CIRCLE_RADIUS":8,
                                                    "CIRCLE_COMPONENT":"r",
                                                    })
    circle_dft_diff         = c_circle_dft_diff_filter()
    circle_dft_diff_combine = c_circle_dft_diff_combine_filter()

    ar = float(imgs[0].width)/imgs[0].height
    to_yuv.set_parameters( {"ysc":2.0, "yc":-1.0, "xsc":2.0*ar, "xc":-1.0-ar*0} )
    to_yuv.execute((imgs[0],tb[0]))
    to_yuv.execute((imgs[1],tb[1]))
    harris.execute( (tb[0],tb[4]) )

    if False: # do windowed equalization to remove brightness and contrastiness dependence - with loss of information
        copy_img.execute((tb[0],tb[0],tb[2]))
        equalize.execute((tb[2],tb[0]))
        copy_img.execute((tb[1],tb[1],tb[2]))
        equalize.execute((tb[2],tb[1]))
        pass
    circle_dft.execute((tb[0],tb[2]))
    circle_dft.execute((tb[1],tb[3]))
    find_corners.execute( (tb[4],) )

    quaternion      = gjslib_c.quaternion
    lp_20 = gjslib_c.lens_projection(width=1024.0, frame_width=36.0, focal_length=20.0, lens_type="rectilinear")
    lp_20.orient(quaternion().lookat((0,0,1),(1,0,0)))
    print find_corners.f.num_points
    corners = find_corners.f.points[:3]
    matches = {}
    for i in range(len(corners)):
        pt = corners[i]
        xy = (pt[0],pt[1])
        for i, dxy in [(0,(4,0)), (1,(0,4)), (2,(-4,0)), (3,(0,-4))]:
            circle_dft_diff.set_parameters( {"uv_base_x":xy[0]+dxy[0], "uv_base_y":xy[1]+dxy[1]} )
            circle_dft_diff.execute( (tb[2], tb[3], tb[5+i]) )
            pass
        circle_dft_diff_combine.execute( (tb[5], tb[6], tb[7], tb[8], tb[9]) )
        find_matches.execute( (tb[9],) )
        matches[xy] = find_matches.f.points[0]
        pass
    def q_inner_product(q1,q2):
        s = 0
        for i in range(4):
            s += q1.rijk[i]*q2.rijk[i]
            pass
        a1 = q1.rotate_vector((0,0,1))
        a2 = q2.rotate_vector((0,0,1))
        s = 0
        for i in range(3):
            s += a1[i]*a2[i]
        return s
    matches[(512,512)]=(500,582)
    for xy in matches.keys():
        print xy," -> ",matches[xy]
        src_q = lp_20.orientation_of_xy((xy[0]-512,xy[1]-512))
        dst_q = lp_20.orientation_of_xy((matches[xy][0]-512,matches[xy][1]-512))
        print src_q, dst_q
        q1q2 = q_inner_product(src_q,dst_q)
        print q1q2, 180/math.pi*math.acos(q1q2)
        #print 2*q1q2*q1q2-1, 180/math.pi*math.acos(2*q1q2*q1q2-1)
        pass
    if False:
        for i in range(10):
            save_as_png(tb[i],"img_dft_%d.png"%i)
            pass
        pass

    pass

#f test_mandel_projection
def test_mandel_projection():
    lens_projection = gjslib_c.lens_projection
    quaternion      = gjslib_c.quaternion

    lp_from = lens_projection(frame_width=36.0, focal_length=40.0, lens_type="equiangular")
    lp_to = lens_projection(frame_width=36.0, focal_length=10.0, lens_type="rectilinear")
    lp_from.orient(quaternion().lookat((0,0,1),(1,0,0)))
    lp_to.orient(quaternion().lookat((0.3,0.3,1),(1,0,0)))

    mandel = c_mandelbrot_filter()
    mandel.execute( (tb[1],tb[0]) )
    #alu_test( [ ((2,2,0), "vec4(abs(sin(200*x*y)*sin(200*(1-x)*y)))",    "test_sin_xy.png"),
    #            ] )

    copy_img = c_alu_filter(extra_defines={"OP":"src_a"})
    copy_img.set_projections(projections=(lp_from,lp_to), num_x_divisions=20, num_y_divisions=20)
    copy_img.execute((tb[0],tb[1],tb[2]))
    for i in range(3):
        save_as_png(tb[i],"img_proj_%d.png"%i)

#f test_lens_projection
def test_lens_projection():
    lens_projection = gjslib_c.lens_projection
    quaternion      = gjslib_c.quaternion

    lp_20 = lens_projection(frame_width=36.0, focal_length=20.0, lens_type="rectilinear")
    lp_30 = lens_projection(frame_width=36.0, focal_length=30.0, lens_type="rectilinear")
    lp_20.orient(quaternion().lookat((0,0,1),(1,0,0)))
    lp_30.orient(quaternion().lookat((0,0,1),(1,0,0)))

    a = quaternion.roll(60, degrees=1)
    print a.rotate_vector((1,0,3))
    print a.rotate_vector((0,1,3))

    lp_20 = lens_projection(frame_width=36.0, focal_length=20.0, lens_type="rectilinear")
    print quaternion.roll(60,degrees=1)
    print quaternion().identity()
    a = quaternion()
    b = quaternion()
    c = quaternion(r=1.0)
    print c
    c = quaternion(r=1, i=2, j=3, k=4) * quaternion(i=1)* quaternion(j=1)* quaternion(k=1)
    print c

    a.scale(2)
    print a.rijk
    a.lookat((1,2,3),(4,5,4))
    b.lookat((1,0,0),(0,1,0))
    print "a", a
    print "b", b
    print "~a", ~a
    print abs(a)
    a.from_rotation((1,1,0),60.0,degrees=1)
    print a
    a.from_euler(pitch=60.0,degrees=1)
    lp_20.orient(a)
    print lp_20
    print "orientation of 0,0",lp_20.orientation_of_xy((0,0))
    print "x,y of orientation of a",lp_20.xy_of_orientation(a)
    a.from_rotation((1,1,0),60.0,degrees=1)
    lp_20.orient(a)
    print lp_20
    print "orientation of 0,0",lp_20.orientation_of_xy((0,0))
    print "x,y of orientation of a",lp_20.xy_of_orientation(a)
    print a
    print lp_20.orientation
    a.scale(2)
    print a
    print lp_20.orientation
    pass

#f test_quaternion_rotation_z
def test_quaternion_rotation_z():
    quaternion = gjslib_c.quaternion
    for w in range(4):
        for x in range(4):
            for y in range(4):
               for z in range(4):
                   q = quaternion(r=w,i=x,j=y,k=z)
                   r = q.rotate_vector((0,0,1))
                   r2 = (2*(z*x-w*y), 2*(w*x+y*z), w*w-x*x-y*y+z*z)
                   for i in range(3):
                       if abs(r[i]-r2[i])>0.000001:
                           print "Error in quaternion rotation"
                           pass
                       pass
                   pass
               pass
            pass
        pass
    pass

#a Toplevel
if False:
    test_to_yuv()

if False:
    test_alu()

if False:
    test_gauss()

if False:
    test_dft_images()

if False:
    test_diff_image()

if False:
    test_diff_image_and_match()

if False:
    test_mandel_projection()

if False:
    test_lens_projection()

if False:
    test_diff_image_quaternion()

if False:
    test_diff_image_quaternion_2()

if True:
    test_diff_image_quaternion_3()

        


